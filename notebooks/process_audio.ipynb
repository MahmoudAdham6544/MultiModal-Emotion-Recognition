{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f4e5ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "# === HELPER: Extract MFCC from one file ===\n",
    "def extract_mfcc(file_path, n_mfcc=40):\n",
    "    y, sr = librosa.load(file_path, sr=None)\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
    "    return mfcc.T  # shape: (time_steps, n_mfcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f6d965af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mfcc_list_songs 1012\n"
     ]
    }
   ],
   "source": [
    "songs_path = r'../data/Unprocessed/Audio_Song_Actors'\n",
    "mfcc_list_songs = []\n",
    "label_list = []\n",
    "max_len = 0\n",
    "for actor in os.listdir(songs_path):\n",
    "    for audio in os.listdir(songs_path +'/'+ actor):\n",
    "        #output_dir = output_parent_dir_songs + '/' + actor + '/' + audio[:-4] #Remove the .wav extension\n",
    "        #os.makedirs(output_dir, exist_ok=True) #Create an output directory for each audio\n",
    "        y, sr = librosa.load(songs_path +'/'+ actor + '/' + audio)\n",
    "        mfcc = extract_mfcc(songs_path +'/'+ actor + '/' + audio, n_mfcc=40) #Extract the MFCC features\n",
    "        mfcc_list_songs.append(mfcc)\n",
    "        label_list.append(audio[:-4])\n",
    "        max_len =  max(max_len, mfcc.shape[0])\n",
    "        \n",
    "padded_mfccs = []\n",
    "for mfcc in mfcc_list_songs:\n",
    "    pad_width = max_len - mfcc.shape[0]\n",
    "    if pad_width > 0:\n",
    "        padded = np.pad(mfcc, ((0, pad_width), (0, 0)), mode='constant')\n",
    "    else:\n",
    "        padded = mfcc\n",
    "    padded_mfccs.append(padded)#Append the MFCC and the audio name to the list\n",
    "print(\"mfcc_list_songs\", len(mfcc_list_songs))\n",
    "merged = [[a, b] for a, b in zip(padded_mfccs, label_list)]\n",
    "processed_audio_songs = np.array(merged, dtype=object) #Convert the list to a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3a2b3f15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mfcc_list_speech 1440\n"
     ]
    }
   ],
   "source": [
    "speech_path = r'../data/Unprocessed/Audio_Speech_Actors'\n",
    "mfcc_list_speech = []\n",
    "label_list = []\n",
    "max_len = 0\n",
    "for actor in os.listdir(speech_path):\n",
    "    for audio in os.listdir(speech_path +'/'+ actor):\n",
    "        y, sr = librosa.load(speech_path +'/'+ actor + '/' + audio)\n",
    "        mfcc = extract_mfcc(speech_path +'/'+ actor + '/' + audio, n_mfcc=40) #Extract the MFCC features\n",
    "        mfcc_list_speech.append(mfcc)\n",
    "        label_list.append(audio[:-4])\n",
    "        max_len =  max(max_len, mfcc.shape[0])\n",
    "        \n",
    "padded_mfccs = []\n",
    "for mfcc in mfcc_list_speech:\n",
    "    pad_width = max_len - mfcc.shape[0]\n",
    "    if pad_width > 0:\n",
    "        padded = np.pad(mfcc, ((0, pad_width), (0, 0)), mode='constant')\n",
    "    else:\n",
    "        padded = mfcc\n",
    "    padded_mfccs.append(padded)#Append the MFCC and the audio name to the list\n",
    "print(\"mfcc_list_speech\", len(mfcc_list_speech))\n",
    "merged = [[a, b] for a, b in zip(padded_mfccs, label_list)]\n",
    "processed_audio_speech = np.array(merged, dtype=object) #Convert the list to a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b47b0882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed_audio 2452\n"
     ]
    }
   ],
   "source": [
    "processed_audio = np.concatenate((processed_audio_songs, processed_audio_speech), axis=0) #Concatenate the two arrays\n",
    "np.save('processed_audio.npy', processed_audio) #Save the array to a file\n",
    "print(\"processed_audio\", len(processed_audio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e38588",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emo_recog",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
